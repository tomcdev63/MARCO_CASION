<!-- TABLE OF CONTENTS -->
## Table of Contents

* [About the Project](#about-the-project)
  * [Built With](#built-with)
* [Getting Started](#getting-started)
  * [Installation](#installation)
* [Usage](#usage)
* [Sources](#sources)

<!-- ABOUT THE PROJECT -->
## About The Project

### Built With

* [Anaconda](https://www.anaconda.com/)

<!-- GETTING STARTED -->
## Getting Started

To get a local copy up and running follow these simple steps.

### Installation

1. Clone the repo

    ```sh
    git clone https://github.com/tomcdev63/Ya_que_la_taille_du_DF.git
    ```

2. Create a conda virtual environment with

    ```sh
    conda create --name <env> --file requirements.txt
    ```

<!-- USAGE EXAMPLES -->
## Usage

* [main.ipynb](https://github.com/tomcdev63/https://github.com/tomcdev63/Ya_que_la_taille_du_DF/blob/main/src/main.ipynb) - our step by step process to create our model.   

## Models
* ```/saved_models/model.h5``` - 10 categories trained model.  
* ```/saved_models/model_data_augmentation.h5``` - 10 categories trained model with data augmentation.

## Sources

* https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator
* https://neptune.ai/blog/data-augmentation-in-python


# CARS üöó

![Screenshot](https://github.com/tomcdev63/MARCO_CASION/blob/main/IMG/E1_marco_casion_DEMO.gif?raw=true)

## Sommaire üìã

* [Contexte du projet](#contexte_du_projet)
* [Construit avec](#construit_avec)
* [Installation](#installation)
* [Usage](#usage)
* [Sources](#sources)

## Contexte du projet ‚úîÔ∏è

La soci√©t√© ¬´¬†Marco Casion¬†¬ª ach√®te des voitures d‚Äôoccasion en Inde. 
Marco (g√©rant de la soci√©t√©) avait pour habitude de faire des offres de reprise via un questionnaire et une r√©ponse par email.
Pour gagner du temps et rendre son offre plus attractive, il a d√©cid√© de moderniser son process en donnant une r√©ponse imm√©diate via son site internet √† l‚Äôaide d‚Äôun formulaire qui prend en compte un certain nombre de crit√®res. Afin d‚Äôattirer les vendeurs, Marco propose des prix de rachat 9% plus √©lev√©s que la moyenne observ√©e pour ce m√™me v√©hicule en Inde. 
C‚Äôest dans ce cadre qu‚Äôil vous sollicite pour r√©aliser l‚Äôapplication qui permettra √† tout vendeur de v√©hicule d‚Äôoccasion de conna√Ætre le tarif de rachat de son v√©hicule par ¬´¬†Marco Casion¬†¬ª.
En termes de donn√©es, cette soci√©t√© met √† disposition une base de donn√©es relationnelle qui contient les caract√©ristiques des v√©hicules d‚Äôoccasion en Inde et leur prix de vente.

## Construit avec ‚öôÔ∏è

* [Anaconda](https://www.anaconda.com/)

## Installation üë®‚Äçüíª

* Clone du repos

    ```sh
    git clone https://github.com/tomcdev63/ML.git
    ```

* Cr√©ation de l'environnement Python

    ```sh
    conda create --name myenv
    ```

* Chargement de l'environnement 

    ```sh
    conda env update -n myenv --file environment.yml
    ```

## Usage üëå
 
* ```src/app/00_CLEAN_BDD.ipynb``` - Notebook concernant l'import des donn√©es et un premier nettoyage rapide.
* ```src/app/00_MAIN_BDD.ipynb``` - Cr√©ation de mod√®les de regression et de leur am√©liorations via des m√©thodes de Cleaning, Feature engineering etc.
* Afin de lancer le site internet en mode local via FASTAPI, rendez-vous dans un CMD --> ```cars/src/app``` puis ex√©cuter la commande ci-dessous : 

    ```sh
    uvicorn main:app --reload
    ```
![Screenshot](https://github.com/tomcdev63/MARCO_CASION/blob/main/IMG/Capture.JPG?raw=true)

## Mod√®les ‚≠ê
* ```data/models/linear_regression_best_78%``` - mod√®le de Regression Lin√©aire avec un r2 √† 78%  
* ```data/models/random_forest_regressor_best_89%``` - mod√®le de Random Forest Regressor avec un r2 √† 89%

## Sources ‚ÑπÔ∏è

* https://fr.wikipedia.org/wiki/R√©gression_lin√©aire#:~:text=Comme%20les%20autres%20mod√®les%20de,des%20valeurs%20particuli√®res%20de%20x
* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html
* https://help.tableau.com/current/pro/desktop/fr-fr/calculating_z_scores.htm
* https://medium.com/swlh/random-forest-and-its-implementation-71824ced454f

## Plan de la base de donn√©es relationnelle üó∫Ô∏è

![Screenshot](https://github.com/tomcdev63/MARCO_CASION/blob/main/IMG/14.JPG?raw=true)

## Mise en place de techniques de monitoring üîç

Gr√¢ce √† la librairie MLFlow les divers tests concernant les algorithmes employ√©s ainsi que leurs hyperparam√®tres (voir Annexe 8) ont pu √™tre sauvegard√©s au sein d‚Äôune interface graphique. Cela a pour but d‚Äôavoir une repr√©sentation visuelle et graphique de l‚Äôensemble des essais effectu√©s ainsi que de d√©tecter et corriger les √©ventuels dysfonctionnements et anomalies pouvant survenir.
Apr√®s avoir fait tourner le notebook regroupant les diff√©rents algorithmes d‚ÄôIA, il suffit alors de lancer le serveur local MLFlow et de se rendre dans le dossier src/app/, puis d‚Äôex√©cuter la commande¬†:  
‚¶Å	mlflow ui 

## Cr√©ation d‚Äôune API ‚öôÔ∏è

Afin de r√©pondre au mieux √† la demande du client, un site internet int√©grant un module d'estimation (indiquant le prix moyen d'une voiture d'occasion reprise en Inde et celui appliqu√© par la soci√©t√© "MARCO CASION"¬†: 9% de plus) a √©t√© mis en place gr√¢ce au framework FastAPI.   
Ainsi les futurs vendeurs d√©sireux de connaitre le prix de rachat de leur v√©hicule par la soci√©t√© Marco Casion n‚Äôauront plus qu‚Äô√† se rendre sur le site de Marco et indiquer les diff√©rents crit√®res de leur v√©hicule afin d‚Äôavoir une estimation du prix de rachat de celui-ci.  
Ce site est accessible en ligne √† l‚Äôadresse :   
‚¶Å	http://ml.car.tomdev.ovh/   
Ou de mani√®re locale, en se rendant dans le dossier src/app/ et en ex√©cutant la commande¬†:   
‚¶Å uvicorn main:app

![Screenshot](https://github.com/tomcdev63/MARCO_CASION/blob/main/IMG/E1_marco_casion_DEMO.gif?raw=true)

## Annexes

‚¶Å	Annexe 1¬†: Normalisation des donn√©es 1Ô∏è‚É£
Source¬†: 
https://dataanalyticspost.com/Lexique/normalisation/#:~:text=Normalisation%20%3A%20La%20normalisation%20est%20une,l'application%20de%20certains%20algorithmes.‚¶Å	&‚¶Å	text=Cette%20m%C3%A9thode%20a%20en%20outre,dans%20la%20fouille%20de%20donn%C3%A9es.   
Normalisation : La normalisation est une m√©thode de pr√©traitement des donn√©es qui permet de r√©duire la complexit√© des mod√®les. C'est √©galement un pr√©alable √† l'application de certains algorithmes. ... Cette m√©thode a en outre de nombreuses applications dans la fouille de donn√©es.

‚¶Å	Annexe 2¬†: MinMaxScaler 0Ô∏è‚É£ 1Ô∏è‚É£
Transforme les entit√©s en adaptant chaque entit√© √† une plage donn√©e. Cet estimateur met √† l'√©chelle et traduit chaque caract√©ristique individuellement de telle sorte qu'elle se situe dans la plage donn√©e sur l'ensemble d'apprentissage, par exemple entre z√©ro et un.

‚¶Å	Annexe 3¬†: OneHotEncoder 0Ô∏è‚É£ 1Ô∏è‚É£
Encode les caract√©ristiques cat√©gorielles sous la forme d'un tableau num√©rique unique. L'entr√©e de ce transformateur doit √™tre un tableau d'entiers ou de cha√Ænes, indiquant les valeurs prises par les caract√©ristiques cat√©gorielles (discr√®tes). Les caract√©ristiques sont encod√©es √† l'aide d'un sch√©ma d'encodage one-hot (alias 'one-of-K' ou 'dummy'). Cela cr√©e une colonne binaire pour chaque cat√©gorie et renvoie une matrice clairsem√©e ou un tableau dense.

‚¶Å	Annexe 4¬†: Hyperparam√®tres üîß
Sources¬†:
‚¶Å	https://fr.wikipedia.org/wiki/Hyperparam%C3%A8tre  

Dans l'apprentissage automatique, un hyperparam√®tre est un param√®tre dont la valeur est utilis√©e pour contr√¥ler le processus d'apprentissage. En revanche, les valeurs des autres param√®tres (g√©n√©ralement la pond√©ration de n≈ìuds) sont obtenues par apprentissage.
Un exemple d'hyperparam√®tre de mod√®le est la topologie et la taille d'un r√©seau de neurones. Des exemples d'hyperparam√®tres d'algorithme sont la vitesse d'apprentissage et la taille des lots.
Les diff√©rents hyperparam√®tres varient en fonction de la nature des algorithmes d'apprentissage, par exemple certains algorithmes d'apprentissage automatique simples (comme la r√©gression des moindres carr√©s) n'en n√©cessitent aucun. Compte tenu de ces hyperparam√®tres, l'algorithme d'apprentissage apprend les param√®tres √† partir des donn√©es. Par exemple, la r√©gression LASSO est un algorithme qui ajoute un hyperparam√®tre de r√©gularisation √† la r√©gression des moindres carr√©s, qui doit √™tre d√©fini avant d'estimer les param√®tres via l'algorithme d'apprentissage.

‚¶Å	Annexe 5¬†: Score (MAE, RMSE, R2) üéØ
MAE¬†: Diff√©rence absolue entre les vraies valeurs et les valeurs pr√©dites.
MSE¬†: Moyenne des √©carts au carr√© entre les vraies valeurs et les valeurs pr√©dites.
RMSE¬†: Correspond √† la racine carr√©e du MSE.
Median ABS error¬†: M√©diane des diff√©rences absolues des erreurs.
CV mean¬†: Moyenne des diff√©rents score R2 produits apr√®s avoir effectu√© un GridSearch.
STD¬†: Dispersion des points autour de la moyenne des diff√©rentes distributions.

‚¶Å	Annexe 6¬†: ZSCORE üí§

En statistiques, le score z (ou score standard) d'une observation d√©signe le nombre d'√©carts-types qui se trouve au-dessus ou en dessous de la moyenne de la population. Pour calculer un r√©sultat z, vous devez conna√Ætre la moyenne de population et l'√©cart-type de population. 
Cr√©er une visualisation de score z pour r√©pondre aux questions du type suivant : 
Quel pourcentage de valeurs est-il inf√©rieur √† une valeur sp√©cifique ? 
Quelles valeurs peuvent √™tre consid√©r√©es comme exceptionnelles ? Par exemple, dans un test de QI, quels scores repr√©sentent les 5 % sup√©rieurs ? 
Quel est le score relatif d'une distribution par rapport √† une autre ? Par exemple, Michael est plus grand que la moyenne des hommes, et Emily est plus grande que la moyenne des femmes, mais qui est plus grand relativement dans son sexe ?

![Screenshot](https://github.com/tomcdev63/MARCO_CASION/blob/main/IMG/z_score.png?raw=true)

‚¶Å	Annexe 7¬†: Regression Lineaire üìà

En statistiques, en √©conom√©trie et en apprentissage automatique, un mod√®le de r√©gression lin√©aire est un mod√®le de r√©gression qui cherche √† √©tablir une relation lin√©aire entre une variable, dite expliqu√©e, et une ou plusieurs variables, dites explicatives.
On parle aussi de mod√®le lin√©aire ou de mod√®le de r√©gression lin√©aire.
Comme les autres mod√®les de r√©gression, le mod√®le de r√©gression lin√©aire est aussi bien utilis√© pour chercher √† pr√©dire un ph√©nom√®ne que pour chercher √† l'expliquer.
Apr√®s avoir estim√© un mod√®le de r√©gression lin√©aire, on peut pr√©dire quel serait le niveau de y pour des valeurs particuli√®res de x. 

‚¶Å	Annexe 8¬†: Random Forest Regressor üå≤

La for√™t al√©atoire est un algorithme d'apprentissage supervis√© qui utilise une m√©thode d'apprentissage d'ensemble pour la classification et la r√©gression.
Les arbres en for√™ts al√©atoires sont ex√©cut√©s en parall√®le. Il n'y a pas d'interaction entre ces arbres lors de la construction des arbres.
Il fonctionne en construisant une multitude d'arbres de d√©cision au moment de l'apprentissage et en produisant la classe qui est le mode des classes (classification) ou la pr√©diction moyenne (r√©gression) des arbres individuels.
Une for√™t al√©atoire est un m√©ta-estimateur (c'est-√†-dire qu'il combine le r√©sultat de plusieurs pr√©dictions) qui agr√®ge de nombreux arbres de d√©cision , avec quelques modifications utiles :
* Le nombre d'entit√©s pouvant √™tre fractionn√©es √† chaque n≈ìud est limit√© √† un certain pourcentage du total (appel√© hyperparam√®tre ). Cela garantit que le mod√®le d'ensemble ne repose pas trop sur une caract√©ristique individuelle et fait un usage √©quitable de toutes les caract√©ristiques potentiellement pr√©dictives .
* Chaque arbre tire un √©chantillon al√©atoire de l'ensemble de donn√©es d'origine lors de la g√©n√©ration de ses divisions, ajoutant un √©l√©ment suppl√©mentaire de caract√®re al√©atoire qui emp√™che le surajustement.

![Screenshot](https://github.com/tomcdev63/MARCO_CASION/blob/main/IMG/Captur%C3%B9%C3%B9e.JPG?raw=true)
